\chapter{Codice}
Il codice del progetto è suddiviso in quattro cartelle ciascuna delle quali si occupa di un aspetto specifico del flusso. Di seguito è riportata la struttura delle cartelle e dei file principali, per avere una panoramica dell'organizzazione del progetto. \\ 

\tikzstyle{every node}=[draw=black,thick,anchor=west]
\tikzstyle{selected}=[draw=red,fill=red!30]
\tikzstyle{optional}=[dashed,fill=gray!50]
\begin{tikzpicture}[%
  grow via three points={one child at (0.5,-0.68) and
  two children at (0.5,-0.71) and (0.5,-1.45)},
  edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
  \node {root/}
    child { node {core/}
        child{ node {ImageToStringClassifier.py}}
        child{ node {ImageToStringPostprocessing.py}}
        child{ node {ImageToStringPreprocessing.py}}
    }
    child [missing] {}
    child [missing] {}
    child [missing] {}
    child { node {dataset/}
        child { node {dataset.ipynb}}
    }
    child [missing] {}
    child { node {demo/}
        child { node {demo.py}}
    }
    child [missing] {}
    child { node {src/}
        child { node {evaluation\_english\_words.ipynb}}
        child { node {evaluation\_random\_words.ipynb}}
        child { node {ImageToStringNet.py}}
        child { node {main.ipynb}}
    }
    child [missing] {}
    child [missing] {}
    child [missing] {}
    child [missing] {};
\end{tikzpicture}

\section{Core}
La cartella \emph{core} contiene il codice delle tre classi dedicate a preprocessing, classificazione e postprocessing.

\subsection{PreProcessing}
La classe \texttt{ImageToStringPreprocessing} prepara l'immagine contenente testo per la fase successiva di classificazione, segmentando le lettere e normalizzandole in un formato uniforme. A partire da un'immagine in input, esegue operazioni come conversione in scala di grigi, binarizzazione e inversione del contrasto se necessario. 
Successivamente, rileva e raggruppa le componenti connesse per identificare le singole lettere, calcolando anche informazioni spaziali come distanze relative e disegnando le relative bounding box sull'immagine originale.
Ogni lettera viene poi ritagliata, ridimensionata proporzionalmente e centrata su un'immagine nera 28x28, rendendola pronta per le fasi successive. La classe inoltre fornisce metodi per accedere all'immagine segmentata, alle lettere preprocessate e alla loro visualizzazione.

\subsection{Classificazione}
A partire da un'immagine contenente una sequenza di caratteri, la classe \texttt{ImageToStringClassifier} gestisce l'intero processo di riconoscimento integrando preprocessing, postprocessing e \texttt{ImageToStringNet} per la classificazione.

\subsection{PostProcessing}
La classe \texttt{ImageToStringPostprocessing} a partire dalla lista delle lettere classificate con relative informazioni spaziali, applica le euristiche discusse nei capitoli precedenti per decidere dove inserire spazi tra parole, basandosi sulle distanze orizzontali tra i caratteri. Inoltre, sfrutta la posizione verticale delle lettere rispetto ai bounding box generale per correggere l'uso errato delle maiuscole e minuscole in caratteri ambigui, confrontando ciascun carattere incerto con il primo considerato affidabile. Il risultato è una sequenza di caratteri più coerente, utile per migliorare l'output finale del sistema di OCR.

\section{Dataset}
La cartella \emph{dataset} contiene il notebook \texttt{dataset.ipynb}, in cui sono descritte e implementate tutte le procedure necessarie per la creazione del dataset.
Sono definite le funzioni per la generazione automatica delle immagini dei caratteri che permettono di creare immagini sintetiche di lettere, al variare di font, dimensioni.
Segue una fase di normalizzazione delle immagini, in cui ciascuna immagine viene convertita in scala di grigi, ridimensionata e centrata su uno sfondo uniforme, 28x28 pixel. Il notebook include anche procedure per la suddivisione del dataset in insiemi di training, validation e test, assicurando che la distribuzione delle classi sia bilanciata.

Viene mostrato come salvare i dati in formato compatibile con PyTorch (\texttt{torch.utils.data.Dataset}) e come importarli rapidamente nei notebook di addestramento e valutazione.

Infine, sono implementate funzioni dedicate alla generazione automatica di parole e frasi. Queste funzioni permettono di creare immagini sintetiche che rappresentano sequenze di caratteri, sia come singole parole sia come frasi complete. La generazione avviene componendo stringhe casuali o selezionate da dizionari di parole, che vengono poi renderizzate su immagini. Per ogni immagine generata, vengono salvate le etichette corrispondenti e le informazioni di segmentazione, utili sia per il training che per la valutazione del modello.
\section{Demo}
La cartella \emph{demo} contiene il file \texttt{demo.py}, che fornisce l'interfaccia semplice per testare il modello descritta nel Capitolo \ref{cap:demo}. Lo script permette di caricare un'immagine, eseguire il preprocessing, la classificazione e visualizzare il risultato finale.
\section{Src}
La cartella \emph{src} contiene i file principali per l'addestramento, la valutazione e l'esecuzione del modello. In particolare:
\begin{itemize}
    \item \texttt{main.ipynb}
    \item \texttt{ImageToStringNet.py}
    \item \texttt{evaluation\_english\_words.ipynb}
    \item \texttt{evaluation\_random\_words.ipynb}
\end{itemize}

\subsection{main.ipynb}
Il notebook \texttt{main.ipynb} rappresenta il fulcro del progetto, integrando tutte le fasi principali del flusso di lavoro. Inizialmente, vengono importate le librerie necessarie e caricati i dati preprocessati dal dataset. Successivamente, avviene fase di preprocessing delle immagini, utilizzando le classi definite nella cartella \emph{core} per segmentare e normalizzare i caratteri. 

Segue la definizione e l'inizializzazione della rete \texttt{ImageToStringNet}, con la possibilità di configurare il numero di classi, il tasso di apprendimento e il dropout. Viene impostato il ciclo di addestramento: per ogni epoca, il modello viene allenato sui dati di training e valutato su quelli di validazione, con il calcolo delle metriche di accuratezza e perdita. Il notebook include anche la visualizzazione grafica dell'andamento di queste metriche per monitorare il processo di training.

Al termine dell'addestramento, il modello migliore viene salvato e testato su un insieme di dati separato, per valutare le prestazioni finali. Sono inoltre presenti sezioni dedicate all'analisi qualitativa dei risultati, con esempi di immagini classificate correttamente e casi di errore, utili per identificare possibili miglioramenti.

\subsection{ImageToStringNet.py}
Il file \texttt{ImageToStringNet.py} contiene l’implementazione della rete neurale convoluzionale (CNN) utilizzata per la classificazione dei caratteri segmentati discussa nel Capitolo~\ref{cap:modello}. La classe principale, \texttt{ImageToStringNet}, estende \texttt{torch.nn.Module}: sono presenti i blocchi convoluzionali con le relative funzioni di attivazione, operazioni di pooling e dropout per la regolarizzazione. Dopo la parte convoluzionale, le feature vengono appiattite e passate a layer fully-connected che producono l’output finale. Il numero di classi e il tasso di dropout sono parametri configurabili. 

\subsection{Notebook per Evaluation}
I notebook \texttt{evaluation\_english\_words.ipynb} ed \\  \texttt{evaluation\_random\_words.ipynb} sono dedicati alla valutazione delle prestazioni del modello su due tipologie di dataset differenti. 

Rispettivamente nel primo notebook, vengono utilizzate immagini di parole prese da un dizionario di termini inglesi. Il notebook carica il modello addestrato, esegue il preprocessing sulle immagini di test, effettua la classificazione e confronta le predizioni con le etichette reali, calcolando accuratezza, precisione e recall.

Nel secondo, la procedura è analoga ma il dataset di test è composto da parole generate casualmente, senza un significato semantico. Questo permette di valutare la robustezza del modello anche su sequenze di caratteri non presenti nel vocabolario, evidenziando eventuali limiti nella generalizzazione.

Entrambi i notebook includono visualizzazione dei risultati, analisi degli errori e confronti tra le prestazioni sui diversi dataset.

