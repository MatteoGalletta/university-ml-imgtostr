\chapter{Esperimenti}
\section*{Setup testing}
Come anticipato precedentemente, il modello scelto ha un'architettura simile a quella di LeNet-5. Trattandosi di un task di classificazione vicino a quello del riconoscimento di cifre scritte a mano, la scelta di un'architettura ispirata a LeNet-5 è stata naturale, essendo consolidata per questo tipo di problemi.
Sono state comunque effettuate delle modifiche rispetto alla classica architettura sopra citata, sia per adattarla alle features del nostro task di classificazione (che prevedono un paio di input in più), sia per poter ottenere risultati migliori in fase di training (aggiungendo un paio di layer di dropout).
\\
Per poter ottenere la miglior combinazioni di iperparametri, sono stati effettuati diversi esperimenti, variando \emph{learning rate}, \emph{batch size}, \emph{dropout rate}, \emph{momentum} e \emph{numero di epoche}.
Per ognuna delle varianti negli iperparametri nella fase di training, viene generato un log TensorBoard che contiene le coppe di \emph{Loss} e \emph{Accuracy} in entrambi i dataset di training e validation. Inoltre, vengono salvati i pesi al termine delle epoche, utile per poterli ricaricare successivamente.
Di seguito vengono evidenziati gli esperimenti effettuati.

\section{Exps 1}
Il primo esperimento prevede l'iterazione di una griglia di parametri presenti all'interno di un file di configurazione. In particolare, la griglia prevede tutte le triple dei seguenti parametri nei corrispettivi range:
\begin{itemize}
    \item \textbf{Learning rate}: \{0.01, 0.001, 0.005, 0.0001, 0.0005\}
    \item \textbf{Dropout rate}: \{0.2, 0.3, 0.4, 0.5\}
    \item \textbf{Momentum}: \{0, 0.5, 0.9\}
\end{itemize}

Essendo un modello piuttosto piccolo, è stato ritenuto opportuno impostare una batch size di \textbf{2560}, garantendo un calcolo del gradiente più preciso comparato a una batch size piccola. Per semplicità, il numero di epoche è fissato a 50.

Questo approccio di \emph{grid search}, per quanto semplice, potrebbe già restituire dei risultati approssimativi sui range più opportuni per risolvere il problema, rendendo possibile ulteriori esperimenti nei range vicini alla tripla migliore. 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/exps1_loss.png}
    \caption{Loss Exps 1}
    \label{fig:exps1_loss}
\end{figure}

Durante la fase di training si è notato come i tempi di training siano dilatati, rendendo questo approccio inefficiente. Inoltre, a colpo d'occhio, durante l'iterazione dei vari iperparametri, si è notato come le prestazioni del modello fossero parecchio scadenti. Qualche training terminava in overfitting evidente, mentre altri sembravano non convergere entro le 50 epoche.

Per queste ragioni, senza ultimare il training con tutte le permutazioni, si è preferito procedere per via iterativa, come approfondito nella sezione successiva.

\section{Exps 2}

La soluzione più efficiente per ottimizzare il flusso precedentemente configurato si è rilevato essere un processo iterativo con l'intervento umano che regola gli iperparametri più opportuni man mano che gli esperimenti avvengono.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/exps2_loss.png}
    \caption{Loss Exps 2}
    \label{fig:exps1_loss}
\end{figure}

Il secondo esperimento evidenzia come, nonostante venga variato il dropout, il fenomeno di overfitting rimanga persistente.

Questo è probabilmente dovuto alla batch size parecchio grande, non consentendo di avere un grado di regolarizzazione sufficiente alto.


\section{Exps 3}

Per ovviare il problema della precedente sperimentazione, si è deciso di ridurre la batch size a \textbf{256}, consentendo di aumentare la regolarizzazione del modello.

Inoltre, un ulteriore tentativo di migliorare il modello si è configurato nella scelta di andare a riutilizzare i migliori pesi man mano che i parametri vengono cambiati. Questo consente di utilizzare un learning rate più basso quando in prossimità del minimo locale.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/exps3_loss.png}
    \caption{Loss Exps 3}
    \label{fig:exps1_loss}
\end{figure}

I tentativi mostrano uno scarso risultato nel combattere la varianza esibita dalle curve di train e loss.


\section{Exps 7}

Ulteriori tentativi di miglioramento non hanno miglioramenti nella risoluzione del problema di overfitting. In compenso, al settimo esperimento, l'accuracy sul validation set è migliorata, raggiungendo un valore di circa l'82\%.
La principale ragione di unoverfitting così evidente è probabilmente dovuta all'ambiguità dei dati e dalle inconsistente nel dataset che rendono impossibile, agli occhi del modello, la corretta distinzione tra i caratteri confondibili, come evidenziato nella sezione apposita. Per questo motivo, per individuare il termine del training ci si è basati sull'accuratezza del validation set, piuttosto che sulla curva di loss.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/exps7_loss.png}
    \caption{Loss Exps 7}
    \label{fig:exps7_loss}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/exps7_accuracy.png}
    \caption{Accuracy Exps 7}
    \label{fig:exps7_acc}
\end{figure}



Il modello finale prevede l'utilizzo di una \textbf{batch size di 16}, un \textbf{learning rate di 0.02}, un \textbf{dropout rate di 0.5} e un \textbf{momentum di 0.5}. Il numero di epoche è fissato a 15, ma il modello scelto ha mostrato il picco di accuratezza al termine della quarta epoca, prima che il fenomeno di overfitting si facesse evidente anche nella curva di accuracy.

\section{Valutazioni}
\label{sec:valutazioni}
Una volta fissati i pesi ottimali del modello, è stata eseguita la valutazione delle prestazioni sul set di test. Per analizzare in modo più approfondito il comportamento del modello, la valutazione è stata condotta sia a livello di singolo carattere che a livello di stringa.

\subsection{Valutazione caratteri}
La valutazione sui singoli caratteri si articolano in diverse analisi:
\begin{itemize}
    \item Analisi score
    \item Curve Precision-Recall
    \item Matrice di confusione
\end{itemize}

\subsubsection*{Analisi score}
Per le migliori run di ciascun esperimento sono state calcolate le metriche di \textbf{accuracy} e \textbf{loss}.

\begin{table}[H]
\centering
\begin{tabular}{c|c|c|c|c}
\textbf{Esperimento} & \textbf{Accuracy} & \textbf{Loss} \\
\hline
1 & 0.80 & 1.80 \\
2 & 0.78 & 1.50 \\
3 & 0.79 & 2.07 \\
... & ... & ... \\
7 & \textbf{0.82} & \textbf{1.23} \\
\end{tabular}
\caption{Metriche di valutazione sugli esperimenti.}
\label{tab:score_analysis}
\end{table}

Dall'analisi della tabella si può osservare come l'esperimento 7 abbia ottenuto le migliori prestazioni.

\subsubsection*{Curve Precision-Recall}
\label{sec:pr_curves}
Le curve Precision-Recall (PR) consentono di analizzare il bilanciamento tra \emph{precision} e \emph{recall} nelle predizioni del modello, mostrando quanto esso riesca a mantenere alta la precisione man mano che aumenta la quantità di caratteri correttamente riconosciuti. Un indicatore sintetico della qualità complessiva è l'area sotto la curva (AUC-PR), che risulta tanto più elevata quanto migliore è la capacità del modello di conciliare accuratezza e sensibilità nel riconoscimento dei caratteri.

In Figura~\ref{fig:pr_curves} sono riportate le curve per un sottoinsieme rappresentativo di classi non confondibili.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pr_curve1.png}
        \caption{PR-curve \{Q\}}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pr_curve2.png}
        \caption{PR-curve \{T\}}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pr_curve3.png}
        \caption{PR-curve \{a\}}
    \end{subfigure}
    \caption{PR-curves per caratteri non confondibili}
    \label{fig:pr_curves}
\end{figure}

Nel complesso, il modello mostra buone prestazioni, con curve PR ampie e stabili per la maggior parte delle classi.

Tuttavia, alcune classi risultano più problematiche a causa della somiglianza con il case opposto.
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pr_curve_conf1.png}
        \caption{PR-curve \{s\}}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pr_curve_conf2.png}
        \caption{PR-curve \{v\}}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pr_curve_conf3.png}
        \caption{PR-curve \{w\}}
    \end{subfigure}
    \caption{PR-curves per caratteri confondibili}
    \label{fig:pr-confondibili}
\end{figure}

Per valutare l'impatto della distinzione tra maiuscole e minuscole, è stata ripetuta l'analisi ignorando il case. Come mostrato in Figura~\ref{fig:pr-ignore}, l'area sotto la curva migliora sensibilmente, suggerendo che una parte consistente degli errori è dovuta a una difficoltà del modello nel distinguere il case piuttosto che a un'incapacità di riconoscere la forma del carattere.
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.30\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pr_ignore1.png}
        \caption{PR-curve \{s/S\}}
    \end{subfigure}
    \begin{subfigure}[t]{0.30\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pr_ignore2.png}
        \caption{PR-curve \{v/V\}}
    \end{subfigure}
    \begin{subfigure}[t]{0.30\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/pr_ignore3.png}
        \caption{PR-curve \{w/W\}}
    \end{subfigure}
    \caption{PR-curves ignorando il case}
    \label{fig:pr-ignore}
\end{figure}
\FloatBarrier
Un caso particolarmente significativo è riportato in Figura~\ref{fig:pr_strange}, dove, nonostante l'ignoramento del case, le prestazioni del modello risultano ancora insoddisfacenti.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.65\textwidth]{images/pr_strange.png}
    \caption{PR-curve per il carattere \{o\}}
    \label{fig:pr_strange}
\end{figure}

Questo comportamento anomalo può essere attribuito a confusioni residue legate alla somiglianza visiva tra questo tipo di caratteri ed i numeri.

\subsubsection*{Matrice di Confusione}
La matrice di confusione fornisce una rappresentazione dettagliata degli errori di classificazione commessi dal modello. Ogni cella \((i, j)\) indica quante volte un carattere appartenente alla classe \(i\) è stato classificato come \(j\).

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.25\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix.png}
        \caption{Standard}
        \label{fig:confusion_matrix}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.25\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/confusion_matrix_case.png}
        \caption{Case insensitive}
        \label{fig:confusion_matrix_case_insensitive}
    \end{subfigure}
    \caption{Confronto tra le matrici di confusione}
    \label{fig:confusion_matrices_comparison}
\end{figure}
\FloatBarrier

Come si può osservare in Figura~\ref{fig:confusion_matrices_comparison}(a), la diagonale principale è ben marcata, indicando che la maggior parte delle predizioni corrisponde correttamente alla classe attesa. Le deviazioni più significative dalla diagonale si concentrano principalmente tra le classi confondibili, spesso legate a differenze di maiuscole e minuscole.

Analizzando la matrice case-insensitive mostrata in Figura~\ref{fig:confusion_matrices_comparison}(b), si osserva una riduzione significativa degli errori di classificazione, confermando quanto discusso nella Sezione~\ref{sec:pr_curves}.


Nel repository del progetto sono disponibili le matrici di confusione completa sotto forma di report HTML.

\subsection{Valutazione parole}
\label{sec:valutazione-stringhe}

Per l'analisi a livello di parola sono state adottate due metriche principali:
\begin{enumerate}
    \item Distanza di edit: (Levenshtein distance\footnote{V. I. Levenshtein, “Binary codes capable of correcting deletions, insertions and reversals,” \textit{Soviet Physics Doklady}, vol. 10, pp. 707-710, 1966.});
    \item \emph{String Accuracy}.
\end{enumerate}

Le metriche sono state calcolate sui due dataset descritti nella Sezione~\ref{sec:dataset_screenshots}.

\subsection*{Distanza di edit}

La distanza di edit (o \emph{Levenshtein distance}) rappresenta il numero minimo di operazioni elementari — inserimenti, cancellazioni o sostituzioni — necessarie per trasformare una stringa nella corrispondente stringa di riferimento (ground truth).  
Per rendere il confronto equo, il valore ottenuto è stato normalizzato rispetto alla lunghezza della parola di riferimento.

Di seguito si riportano le principali statistiche estratte.

\begin{table}[htbp]
    \centering
    \begin{tabular}{lcccc}
        \toprule
        Dataset                 & Min   & Max   & Mean  & Std   \\
        \midrule
        Stringhe casuali       & 0  & 40 & 5.43  & 23.09 \\
        Stringhe inglesi & 0  & 2212 & 54.646  & 27467.36 \\
        \bottomrule
    \end{tabular}
    \caption{Statistiche distanza di edit}
    \label{tab:edit_distance_stats}
\end{table}

Da questi risultati emergono alcuni comportamenti anomali del modello, in particolare una marcata difficoltà nell'elaborazione di font molto sottili. Come evidenziato in Figura~\ref{fig:thin_fonts_bboxes}, il modello fatica a rilevare correttamente i tratti dei caratteri sottili, principalmente a causa dei bounding box. I riquadri generati in questi casi limite risultano spesso mal posizionati o incompleti, compromettendo i dati in ingresso e ostacolando la corretta interpretazione del carattere.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/thin_font1.png}
        \caption{Immagine originale}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/thin_font1_preproc.png}
        \caption{Bounding box errato}
    \end{subfigure}

    \caption{Bounding box errati con font sottili}
    \label{fig:thin_fonts_bboxes}
\end{figure}

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Ground Truth} & \textbf{Output} \\
        \hline
        \texttt{PEj\%6DuZi8} & \texttt{[:.\ E-j\ :C:::\ :::\ [:::\ é...Z.\ !d} \\
        \hline
        \texttt{unzmu\#QRRu} & \texttt{é...\ eN.Z\ .-NP-N.\ é...@\ :::\textbackslash..\ [:\ [:\ é...} \\
        \hline
    \end{tabular}
    \caption{Esempi di riconoscimenti errati}
    \label{tab:recognition_examples}
\end{table}

\subsection*{String Accuracy}
La string accuracy è definita come la percentuale di stringhe riconosciute esattamente nella loro interezza.

Per una valutazione più dettagliata, sono state considerate le seguenti varianti di string accuracy, che tengono conto di diverse esigenze di confronto:

\begin{itemize}
    \item \textbf{Accuracy case sensitive (CS)}: confronto rigoroso che distingue tra maiuscole e minuscole;
    \item \textbf{Accuracy case insensitive (CI)}: confronto che ignora le differenze tra maiuscole e minuscole, utile per valutare la capacità di distinguere caratteri simili o confondibili;
    \item \textbf{Accuracy case sensitive senza spazi (CSNS)}: confronto che ignora gli spazi ma distingue tra maiuscole e minuscole, utile per valutare la capacità di riconoscimento senza considerare errori di spaziatura.
    \item \textbf{Accuracy case insensitive senza spazi (CINS)}: confronto che ignora sia il case sia gli spazi, utile per gestire eventuali errori di segmentazione o spaziatura

\end{itemize}

La tabella seguente riporta i valori di string accuracy per ciascuna casistica, calcolati separatamente sui due dataset degli screenshot.

\begin{table}[htbp]
    \centering
    \begin{tabular}{lccccc}
        \toprule
        Dataset & CS & CI & CSNS & CINS & CINS* \\
        \midrule
        Stringhe casuali & 2.4 & 3.60 & 43.80 & 47.00 & ?? \\
        Stringhe inglesi & 6.47 & 9.93 & 11.93 & 18.80 & ?? \\
        \bottomrule
    \end{tabular}
    \caption{Risultati string accuracy}
    \label{tab:string_accuracy_stats}
\end{table}

Gran parte degli errori riscontrati deriva dalle euristiche utilizzate nel post-processing, in particolare quelle legate alla generazione degli spazi tra le parole.  
Inoltre, per capire l'impatto delle lettere visivamente simili, come lo zero rispetto alla lettera “O” o la “I” rispetto alla “L”, abbiamo definito una versione estesa della metrica CINS, indicata come \textbf{CINS*}, che considera corretti anche queste confusioni.  
Come si osserva nella Tabella~\ref{tab:string_accuracy_stats}, l'inclusione di questi casi comporta un ulteriore miglioramento della string accuracy, particolarmente evidente nel caso delle stringhe casuali.